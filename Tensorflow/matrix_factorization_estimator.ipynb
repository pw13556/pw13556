{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from data import dataprep\n",
    "from tensorflow.contrib import layers\n",
    "from tensorflow.contrib.learn import *\n",
    "from tensorflow.contrib.learn.python.learn.estimators import model_fn as model_fn_lib\n",
    "from tensorflow.python.estimator.inputs import numpy_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict, test_dict = dataprep.mf_train_test()\n",
    "rating_train = train_dict.pop(\"rating\")\n",
    "rating_test = test_dict.pop(\"rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_params = dict(\n",
    "    n_user=train_dict['user_id'].max() + 1,\n",
    "    n_movie=train_dict['movie_id'].max() + 1,\n",
    "    n_dim=20,\n",
    "    reg_param=0.01,\n",
    "    learning_rate=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mf_function(features, targets, mode, params):\n",
    "    users = features['user_id']\n",
    "    movies = features['movie_id']\n",
    "    ratings = targets\n",
    "\n",
    "    with tf.variable_scope(\"embedding\"):\n",
    "        user_weight = tf.get_variable(\"user_w\"\n",
    "                                      , shape=[params['n_user'], params['n_dim']]\n",
    "                                      , dtype=tf.float32\n",
    "                                      , initializer=layers.xavier_initializer())\n",
    "        user_bias = tf.get_variable(\"user_b\"\n",
    "                                    , shape=[params['n_user']]\n",
    "                                    , dtype=tf.float32\n",
    "                                    , initializer=tf.zeros_initializer)\n",
    "        movie_weight = tf.get_variable(\"movie_w\"\n",
    "                                       , shape=[params['n_movie'], params['n_dim']]\n",
    "                                       , dtype=tf.float32\n",
    "                                       , initializer=layers.xavier_initializer())\n",
    "        movie_bias = tf.get_variable(\"movie_b\"\n",
    "                                     , shape=[params['n_movie']]\n",
    "                                     , dtype=tf.float32\n",
    "                                     , initializer=tf.zeros_initializer)\n",
    "        for v in tf.trainable_variables():\n",
    "            tf.summary.histogram(name=v.name.replace(\":0\",\"\"), values=v)\n",
    "\n",
    "    with tf.name_scope(\"inference\"):\n",
    "        user_emb = tf.nn.embedding_lookup(user_weight, users)\n",
    "        u_b = tf.nn.embedding_lookup(user_bias, users)\n",
    "        movie_emb = tf.nn.embedding_lookup(movie_weight, movies)\n",
    "        m_b = tf.nn.embedding_lookup(movie_bias, movies)\n",
    "        pred = tf.reduce_sum(tf.multiply(user_emb, movie_emb), 1) + u_b + m_b\n",
    "\n",
    "    with tf.name_scope(\"loss\"):\n",
    "        reg_loss = layers.apply_regularization(layers.l2_regularizer(scale=params['reg_param']),\n",
    "                                               weights_list=[user_weight, movie_weight])\n",
    "        loss = tf.nn.l2_loss(pred - ratings) + reg_loss\n",
    "        rmse = tf.sqrt(tf.reduce_mean(tf.pow(pred - ratings, 2)))\n",
    "        \n",
    "\n",
    "    eval_metric_ops = {'rmse': rmse}\n",
    "    train_op = layers.optimize_loss(\n",
    "        loss=loss,\n",
    "        global_step=tf.contrib.framework.get_global_step(),\n",
    "        learning_rate=params[\"learning_rate\"],\n",
    "        optimizer=tf.train.AdamOptimizer,\n",
    "        summaries=[\n",
    "            \"learning_rate\",\n",
    "            \"loss\",\n",
    "            \"gradients\",\n",
    "            \"gradient_norm\",\n",
    "        ])\n",
    "\n",
    "    return ModelFnOps(mode=mode, predictions=pred, loss=loss,\n",
    "                      train_op=train_op, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# input queue for training\n",
    "train_input_fn = numpy_io.numpy_input_fn(\n",
    "    x=train_dict, y=rating_train, batch_size=10000, shuffle=True, num_epochs=None)\n",
    "# input queue for evaluation on test data\n",
    "test_input_fn = numpy_io.numpy_input_fn(\n",
    "    x=test_dict, y=rating_test, batch_size=rating_test.shape[0], shuffle=False, num_epochs=None)\n",
    "\n",
    "monitor_test = monitors.ValidationMonitor(input_fn=test_input_fn, eval_steps=1, every_n_steps=10,\n",
    "                                                name='test')\n",
    "\n",
    "monitor_train = monitors.ValidationMonitor(input_fn=train_input_fn, eval_steps=1, every_n_steps=10,\n",
    "                                                name='train')\n",
    "\n",
    "mf_estimator = Estimator(\n",
    "    model_fn=mf_function,\n",
    "    params=model_params,\n",
    "    model_dir='_summary/mf_estimator',\n",
    "    config=RunConfig(save_checkpoints_secs=5))\n",
    "\n",
    "mf_estimator.fit(input_fn=train_input_fn, steps=400, monitors=[monitor_test, monitor_train])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
