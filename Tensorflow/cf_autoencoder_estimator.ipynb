{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from data import dataprep\n",
    "from tensorflow.contrib import layers\n",
    "from tensorflow.contrib.learn import *\n",
    "\n",
    "from tensorflow.contrib.learn.python.learn.estimators import model_fn as model_fn_lib\n",
    "from tensorflow.python.estimator.inputs import numpy_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_arr, test_arr, train_eval_arr = dataprep.ae_train_test()\n",
    "\n",
    "train_rating = {'ratings': train_arr.astype(np.float32)}\n",
    "test_eval_rating = {'ratings': train_eval_arr.astype(np.float32), 'targets': test_arr.astype(np.float32)}\n",
    "train_eval_rating = {'ratings': train_eval_arr.astype(np.float32), 'targets': train_eval_arr.astype(np.float32)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def auto_encoder(features, targets, mode, params):\n",
    "    ratings = features['ratings']\n",
    "\n",
    "    with tf.name_scope(\"dense_to_sparse\"):\n",
    "        idx = tf.where(tf.not_equal(ratings, 0.0))\n",
    "        sparse_ratings = tf.SparseTensor(idx, tf.gather_nd(ratings, idx), ratings.get_shape())\n",
    "\n",
    "    with tf.variable_scope(\"encoder\"):\n",
    "        encoder_w = tf.get_variable(\"e_w\", shape=[params['n_users'], params['n_dims']])\n",
    "        encoder_b = tf.get_variable(\"e_b\", shape=[params['n_dims']], initializer=tf.zeros_initializer)\n",
    "\n",
    "        encoding_op = tf.sigmoid(tf.sparse_tensor_dense_matmul(sparse_ratings, encoder_w) + encoder_b)\n",
    "\n",
    "    with tf.variable_scope(\"decoder\"):\n",
    "        decoder_w = tf.get_variable(\"d_w\", shape=[params['n_dims'], params['n_users']])\n",
    "        decoder_b = tf.get_variable(\"d_b\", shape=[params['n_users']], initializer=tf.zeros_initializer)\n",
    "\n",
    "        decoding_op = tf.identity(tf.matmul(encoding_op, decoder_w) + decoder_b)\n",
    "\n",
    "    loss = None\n",
    "    rmse = None\n",
    "    if mode != model_fn_lib.ModeKeys.INFER:\n",
    "        with tf.name_scope(\"loss\"):\n",
    "            # backpropagate only partial observed ratings\n",
    "            neg_sparse_decoding = tf.SparseTensor(idx, tf.negative(tf.gather_nd(decoding_op, idx)),\n",
    "                                                  decoding_op.get_shape())\n",
    "            reg_loss = layers.apply_regularization(layers.l2_regularizer(scale=params['l2reg']),\n",
    "                                                   weights_list=[encoder_w, decoder_w])\n",
    "            diff = tf.sparse_add(sparse_ratings, neg_sparse_decoding).values\n",
    "            loss = tf.reduce_mean(tf.square(diff)) + reg_loss\n",
    "    if mode == model_fn_lib.ModeKeys.EVAL:\n",
    "        with tf.name_scope(\"eval_loss\"):\n",
    "            targets = features['targets']\n",
    "            target_idx = tf.where(tf.not_equal(targets, 0.0))\n",
    "            sparse_targets = tf.SparseTensor(target_idx, tf.gather_nd(targets, target_idx), targets.get_shape())\n",
    "            neg_sparse_decoding = tf.SparseTensor(target_idx, tf.negative(tf.gather_nd(decoding_op, target_idx)),\n",
    "                                                  decoding_op.get_shape())\n",
    "            diff = tf.sparse_add(sparse_targets, neg_sparse_decoding).values\n",
    "            rmse = tf.sqrt(tf.reduce_mean(tf.square(diff)))\n",
    "\n",
    "    for v in tf.trainable_variables():\n",
    "        tf.summary.histogram(name=v.name.replace(\":0\",\"\"), values=v)\n",
    "\n",
    "    predictions = decoding_op\n",
    "    eval_metric_ops = {'rmse': rmse}\n",
    "    train_op = layers.optimize_loss(\n",
    "        loss=loss,\n",
    "        global_step=tf.contrib.framework.get_global_step(),\n",
    "        learning_rate=params[\"learning_rate\"],\n",
    "        optimizer=tf.train.AdamOptimizer,\n",
    "        summaries=[\n",
    "            \"learning_rate\",\n",
    "            \"loss\",\n",
    "            \"gradients\",\n",
    "            \"gradient_norm\",\n",
    "        ])\n",
    "\n",
    "    return ModelFnOps(mode, predictions, loss, train_op, eval_metric_ops)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_params = dict(\n",
    "    n_items=train_arr.shape[0],\n",
    "    n_users=train_arr.shape[1],\n",
    "    n_dims=40,\n",
    "    l2reg=0.001,\n",
    "    learning_rate=0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input queue for training\n",
    "train_input_fn = numpy_io.numpy_input_fn(\n",
    "    x=train_rating, y=np.zeros(shape=[train_arr.shape[0], 1]), batch_size=256, shuffle=True, num_epochs=None)\n",
    "# input queue for evaluation on test data\n",
    "test_eval_input_fn = numpy_io.numpy_input_fn(\n",
    "    x=test_eval_rating, y=np.zeros(shape=[test_arr.shape[0], 1]), batch_size=test_arr.shape[0], shuffle=False,\n",
    "    num_epochs=None)\n",
    "# input queue for evaluation on training data\n",
    "train_eval_input_fn = numpy_io.numpy_input_fn(\n",
    "    x=train_eval_rating, y=np.zeros(shape=[test_arr.shape[0], 1]), batch_size=test_arr.shape[0], shuffle=False,\n",
    "    num_epochs=None)\n",
    "\n",
    "monitor_test = monitors.ValidationMonitor(input_fn=test_eval_input_fn, eval_steps=1, every_n_steps=100,\n",
    "                                                name='test')\n",
    "monitor_train = monitors.ValidationMonitor(input_fn=train_eval_input_fn, eval_steps=1, every_n_steps=100,\n",
    "                                           name='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_cf = Estimator(\n",
    "    model_fn=auto_encoder,\n",
    "    params=model_params,\n",
    "    model_dir='_summary/auto_rec',\n",
    "    config=RunConfig(save_checkpoints_secs=10))\n",
    "\n",
    "autoencoder_cf.fit(input_fn=train_input_fn, steps=5000, monitors=[monitor_test, monitor_train])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
